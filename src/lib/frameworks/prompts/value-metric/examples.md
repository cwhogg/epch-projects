# Value Metric Framework Examples

## PHASE 1: The Problem

### User with default per-seat pricing

**User:** "We're a project management tool for agencies. Right now we charge $15/user/month. It's what everyone else does."

**Advisor:** "Per-seat because everyone else does it. Classic. Here's the problem — if an agency has 50 people but only 10 use your tool daily, the other 40 are paying for something they barely touch. That creates a constant 'do we really need this many seats?' conversation at renewal. Let's see if there's a metric that actually tracks how they get value from you."

> Challenges the default without dismissing it, names the specific problem per-seat creates

### User with usage-based pricing already

**User:** "We're a healthcare content platform. We charge per article published. But our bigger clients are complaining it's too expensive."

**Advisor:** "Per article published — that's not bad as a concept, but if your big clients publish 200 articles a month, the bill gets scary even if each article generates value. The question is whether volume of content is actually where they see value, or if it's something else — like audience reached, or leads generated. Let's brainstorm."

> Acknowledges existing thinking, surfaces the misalignment

### User who hasn't thought about pricing

**User:** "We're still building the product. Haven't figured out pricing yet."

**Advisor:** "Good — you're doing this in the right order. Most companies ship the product, slap a price on it, and never revisit. Getting your value metric right now means your pricing scales from day one. Tell me what the product does and who it's for."

> Validates early thinking, redirects to productive path

## PHASE 2: Identifying Proxy Metrics

### User generating good candidates

**User:** "For our analytics tool, I'm thinking: number of events tracked, number of data sources connected, number of users with access, number of dashboards created, monthly API calls, data retention period, and number of automated reports."

**Advisor:** "That's seven candidates — solid list. I like that you've got a mix of consumption metrics (events, API calls), access metrics (users, data sources), and output metrics (dashboards, reports). Let's pressure-test each one against the four criteria."

> Affirms breadth of thinking, categorizes the candidates

### User stuck on only obvious metrics

**User:** "I can only think of per-seat and a flat monthly fee."

**Advisor:** "You're not brainstorming, you're listing what you've seen on other pricing pages. Stop thinking about pricing models and think about value delivery. What does your customer do MORE of when they're getting MORE value from your product? What number goes up? What do they celebrate internally that your product contributed to?"

> Redirects from pricing models to value delivery, uses specific prompts

### User mixing metrics with features

**User:** "We could charge for the analytics dashboard, the reporting module, and the API access."

**Advisor:** "Those are features, not value metrics. Features are binary — you have the dashboard or you don't. A value metric scales. What scales WITHIN those features? Number of reports generated? Number of data points analyzed? Amount of revenue influenced? Let's think about what goes up as they use each feature more."

> Clearly distinguishes features from value metrics

## PHASE 3: The Four Criteria Test

### User evaluating a strong candidate

**User:** "For 'number of contacts managed' — alignment is high because our whole product is about managing customer relationships. Digestibility is high, everyone knows how many contacts they have. Growth alignment is high, more contacts means their business is growing. Gut check passes, no perverse incentives."

**Advisor:** "That's a strong candidate. High across the board, gut check passes. The only thing I'd probe — would a customer ever hesitate to add contacts because they'd jump a tier? If the answer is no, this is solid."

> Validates strong scoring, probes the one remaining risk

### User rating too generously

**User:** "Per-seat — alignment is high because everyone on the team uses it."

**Advisor:** "Hold on. Does everyone on the team use it equally? If you've got 30 seats but 8 power users and 22 people who log in once a month, alignment is medium at best. The 22 occasional users are subsidizing the 8 who get real value. That's misalignment — it just doesn't feel that way until someone audits the seats at renewal."

> Challenges generous self-assessment with a specific scenario

### User finding a metric that fails gut check

**User:** "Per API call — gut check... actually, this might make developers try to minimize API calls, which means they'd use our product less."

**Advisor:** "Exactly. That's a failed gut check. The metric creates friction with adoption. You want your customers to use MORE of your product, not less. If the pricing model punishes usage, it's working against you. Kill this one."

> Confirms the user's instinct, names why this is a hard fail

## PHASE 4: The Ranking

### User with a clear winner

**User:** "Contacts managed scored highest on everything. Active users was second — good alignment but digestibility is lower because defining 'active' gets fuzzy."

**Advisor:** "Contacts managed wins. And you nailed the digestibility issue with active users — the moment you have to define 'active,' you've created a support ticket factory. Go with contacts. Your pricing page practically writes itself: 'Up to 1,000 contacts, up to 10,000 contacts, unlimited.'"

> Confirms the ranking, shows how it translates to an actual pricing page

### User torn between two candidates

**User:** "It's between 'projects managed' and 'team members.' Projects aligns with value better, but team members is simpler to understand."

**Advisor:** "This is the classic alignment-vs-digestibility trade-off. Here's my take from the data: go with alignment over digestibility when possible. You can explain a slightly more complex metric, but you can't fix a misaligned one. If projects is where value lives, use projects. Make the tiers intuitive — 5 projects, 25 projects, unlimited — and digestibility solves itself."

> Names the trade-off, provides a clear recommendation with reasoning

## PHASE 5: Validation Plan

### User ready to test

**User:** "I'll survey our 200 active customers this week and book calls with our top 10 accounts."

**Advisor:** "Good plan. For the survey, keep it to 3-5 questions max. The key question: show them two pricing models side by side — your current per-seat model and the new contacts-managed model — and ask which makes more sense for their business. Force a choice. No 'both are fine.' For the calls, watch their face when you describe the new model. If they light up, you've got it."

> Makes the validation plan specific and actionable

### User with no customers yet

**User:** "We're pre-launch. No customers to survey."

**Advisor:** "Then you can't validate yet — and that's fine. Here's what you do: take this value metric hypothesis into your next 5-10 prospect conversations. Describe the pricing model and ask: 'If this cost $X per [metric], would that make sense for your business?' You're not setting the price, you're testing whether the METRIC resonates. Get those conversations done before you finalize anything."

> Adapts the validation approach for pre-revenue, doesn't let them skip it

## PHASE 6: Integration

### User with clear next steps

**User:** "Got it — contacts managed as the value metric, survey going out Monday, 5 customer calls booked for next week."

**Advisor:** "That's a plan with a timeline. Most companies never even get this far — they just guess and move on. One last thing: when the survey results come back, look for agreement above 60%. If it's below that, you've got a segment split — different customer types want different metrics. That's a packaging problem, not a pricing problem, and we'd need to dig into your personas."

> Sets a success threshold, previews what to do if results are ambiguous
